{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4898b2bf",
   "metadata": {},
   "source": [
    "## Google cloud platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Authenticate and create a client to access Google Cloud Storage\n",
    "auth.authenticate_user()\n",
    "service = build(\"storage\", \"v1\")\n",
    "\n",
    "# Load the Iris dataset from Google Cloud Storage\n",
    "bucket_name = \"your-bucket-name\"\n",
    "file_name = \"iris.csv\"\n",
    "request = service.objects().get_media(bucket=bucket_name, object=file_name)\n",
    "iris_data = pd.read_csv(BytesIO(request.read()))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(iris_data.drop(\"species\", axis=1), iris_data[\"species\"], test_size=0.2)\n",
    "\n",
    "# Define a list of models to train\n",
    "models = [RandomForestClassifier(), GradientBoostingClassifier(), LogisticRegression()]\n",
    "model_names = [\"Random Forest\", \"Gradient Boosting\", \"Logistic Regression\"]\n",
    "\n",
    "# Store the results in a pandas DataFrame\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Accuracy\"])\n",
    "\n",
    "# Train each model and evaluate its accuracy\n",
    "for model, model_name in zip(models, model_names):\n",
    "    model.fit(train_data, train_labels)\n",
    "    val_predictions = model.predict(val_data)\n",
    "    accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    \n",
    "    results = results.append({\"Model\": model_name, \"Accuracy\": accuracy}, ignore_index=True)\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2fb5b",
   "metadata": {},
   "source": [
    "# Amazon web services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5749dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Connect to S3 and load the Iris dataset\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3_object = s3.get_object(Bucket=\"your-bucket-name\", Key=\"iris.csv\")\n",
    "iris_data = pd.read_csv(io.BytesIO(s3_object[\"Body\"].read()))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(iris_data.drop(\"species\", axis=1), iris_data[\"species\"], test_size=0.2)\n",
    "\n",
    "# Define a list of models to train\n",
    "models = [RandomForestClassifier(), GradientBoostingClassifier(), LogisticRegression()]\n",
    "model_names = [\"Random Forest\", \"Gradient Boosting\", \"Logistic Regression\"]\n",
    "\n",
    "# Store the results in a pandas DataFrame\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Accuracy\"])\n",
    "\n",
    "# Train each model and evaluate its accuracy\n",
    "for model, model_name in zip(models, model_names):\n",
    "    model.fit(train_data, train_labels)\n",
    "    val_predictions = model.predict(val_data)\n",
    "    accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    \n",
    "    results = results.append({\"Model\": model_name, \"Accuracy\": accuracy}, ignore_index=True)\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d491d",
   "metadata": {},
   "source": [
    "## Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azureml-sdk\n",
    "\n",
    "import pandas as pd\n",
    "from azureml.core import Workspace, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset from Azure Machine Learning\n",
    "workspace = Workspace.from_config()\n",
    "dataset = Dataset.get_by_name(workspace, name=\"iris-dataset\")\n",
    "iris_data = dataset.to_pandas_dataframe()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(iris_data.drop(\"species\", axis=1), iris_data[\"species\"], test_size=0.2)\n",
    "\n",
    "# Define a list of models to train\n",
    "models = [RandomForestClassifier(), GradientBoostingClassifier(), LogisticRegression()]\n",
    "model_names = [\"Random Forest\", \"Gradient Boosting\", \"Logistic Regression\"]\n",
    "\n",
    "# Store the results in a pandas DataFrame\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Accuracy\"])\n",
    "\n",
    "# Train each model and evaluate its accuracy\n",
    "for model, model_name in zip(models, model_names):\n",
    "    model.fit(train_data, train_labels)\n",
    "    val_predictions = model.predict(val_data)\n",
    "    accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    \n",
    "    results = results.append({\"Model\": model_name, \"Accuracy\": accuracy}, ignore_index=True)\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
